{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tolga\\miniconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "df = pd.read_csv('Data/Loan_status_2007-2020Q3_small.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding_append(source_df, target_df, column):\n",
    "    unique_values = source_df[column].unique()\n",
    "    for value in unique_values:\n",
    "        target_df[f'{column}_{value.lower()}'] = (source_df[column] == value).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_df = df.copy()\n",
    "\n",
    "one_hot_encode_columns = ['term',\n",
    " 'home_ownership',\n",
    " 'hardship_flag',\n",
    " 'debt_settlement_flag',\n",
    " 'pymnt_plan',\n",
    " 'addr_state',\n",
    " 'application_type']\n",
    "\n",
    "for column in one_hot_encode_columns:\n",
    "    one_hot_encoding_append(df, loans_df, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reprinting 4 years --> 4\n",
      "Reprinting 2 years --> 2\n",
      "Reprinting 10+ years --> 10\n",
      "Reprinting 3 years --> 3\n",
      "Reprinting 5 years --> 5\n",
      "Reprinting 6 years --> 6\n",
      "Reprinting 1 year --> 1\n",
      "Reprinting 7 years --> 7\n",
      "Reprinting < 1 year --> 0\n",
      "Reprinting 9 years --> 9\n",
      "Reprinting 8 years --> 8\n"
     ]
    }
   ],
   "source": [
    "# Convert int_rate to float\n",
    "loans_df['int_rate'] = loans_df['int_rate'].str.rstrip('%').astype(float)/100\n",
    "loans_df['revol_util'] = loans_df['revol_util'].str.rstrip('%').astype(float)/100\n",
    "# Convert objects to datetime\n",
    "loans_df['earliest_cr_line'] = pd.to_datetime(loans_df['earliest_cr_line'],format = '%b-%Y')\n",
    "loans_df['issue_d'] = pd.to_datetime(loans_df['issue_d'],format = '%b-%Y')\n",
    "loans_df['last_pymnt_d'] = pd.to_datetime(loans_df['last_pymnt_d'],format = '%b-%Y')\n",
    "\n",
    "emp_length_value_to_years = {'4 years': 4, '2 years': 2, '10+ years': 10, '3 years': 3, '5 years': 5, '6 years': 6, '1 year': 1, '7 years': 7, '< 1 year': 0, '9 years': 9, '8 years': 8}\n",
    "for (key, value) in emp_length_value_to_years.items():\n",
    "    print(f'Reprinting {key} --> {value}')\n",
    "    loans_df.loc[df['emp_length'] == key, 'emp_length'] = value\n",
    "    \n",
    "loans_df.rename(columns={'emp_length': 'emp_length_year'}, inplace=True)\n",
    "loans_df['emp_length_year'] = loans_df['emp_length_year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n']\n"
     ]
    }
   ],
   "source": [
    "# Drop the column pymnt_plan, since the only value is 'n'\n",
    "print(df['pymnt_plan'].unique())\n",
    "\n",
    "one_hot_encode_columns.append('pymnt_plan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully paid = 1, Charged off = 0\n",
    "loans_df['loan_status'] = loans_df['loan_status'].astype('category').cat.codes\n",
    "# A1=0, A2=1, A3=2, ... : Lower the better\n",
    "loans_df['sub_grade'] = loans_df['sub_grade'].astype('category').cat.codes\n",
    "one_hot_encode_columns.append('grade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_df.drop(columns=one_hot_encode_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop dates\n",
    "drop_dates = []\n",
    "for (ix, typ) in enumerate(loans_df.dtypes):\n",
    "    if (typ == '<M8[ns]'):\n",
    "        drop_dates.append(loans_df.columns[ix])\n",
    "        \n",
    "loans_df.drop(columns = drop_dates, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_length_year</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>dti</th>\n",
       "      <th>fico_range_low</th>\n",
       "      <th>fico_range_high</th>\n",
       "      <th>...</th>\n",
       "      <th>addr_state_sd</th>\n",
       "      <th>addr_state_dc</th>\n",
       "      <th>addr_state_ne</th>\n",
       "      <th>addr_state_ia</th>\n",
       "      <th>addr_state_ms</th>\n",
       "      <th>addr_state_id</th>\n",
       "      <th>addr_state_me</th>\n",
       "      <th>addr_state_nd</th>\n",
       "      <th>application_type_individual</th>\n",
       "      <th>application_type_joint app</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42536</th>\n",
       "      <td>12000.0</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>392.81</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.62</td>\n",
       "      <td>720.0</td>\n",
       "      <td>724.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42537</th>\n",
       "      <td>4800.0</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>157.13</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>39600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.49</td>\n",
       "      <td>755.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42538</th>\n",
       "      <td>27050.0</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>885.46</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.87</td>\n",
       "      <td>730.0</td>\n",
       "      <td>734.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42539</th>\n",
       "      <td>12000.0</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>373.94</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>96500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.61</td>\n",
       "      <td>705.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42540</th>\n",
       "      <td>14000.0</td>\n",
       "      <td>0.1285</td>\n",
       "      <td>470.71</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>88000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.02</td>\n",
       "      <td>670.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loan_amnt  int_rate  installment  sub_grade  emp_length_year  \\\n",
       "42536    12000.0    0.1099       392.81          6                4   \n",
       "42537     4800.0    0.1099       157.13          6                2   \n",
       "42538    27050.0    0.1099       885.46          6               10   \n",
       "42539    12000.0    0.0762       373.94          2                3   \n",
       "42540    14000.0    0.1285       470.71          8                4   \n",
       "\n",
       "       annual_inc  loan_status    dti  fico_range_low  fico_range_high  ...  \\\n",
       "42536     60000.0            1   4.62           720.0            724.0  ...   \n",
       "42537     39600.0            1   2.49           755.0            759.0  ...   \n",
       "42538     55000.0            1  22.87           730.0            734.0  ...   \n",
       "42539     96500.0            1  12.61           705.0            709.0  ...   \n",
       "42540     88000.0            1  10.02           670.0            674.0  ...   \n",
       "\n",
       "       addr_state_sd  addr_state_dc  addr_state_ne  addr_state_ia  \\\n",
       "42536              0              0              0              0   \n",
       "42537              0              0              0              0   \n",
       "42538              0              0              0              0   \n",
       "42539              0              0              0              0   \n",
       "42540              0              0              0              0   \n",
       "\n",
       "       addr_state_ms  addr_state_id  addr_state_me  addr_state_nd  \\\n",
       "42536              0              0              0              0   \n",
       "42537              0              0              0              0   \n",
       "42538              0              0              0              0   \n",
       "42539              0              0              0              0   \n",
       "42540              0              0              0              0   \n",
       "\n",
       "       application_type_individual  application_type_joint app  \n",
       "42536                            1                           0  \n",
       "42537                            1                           0  \n",
       "42538                            1                           0  \n",
       "42539                            1                           0  \n",
       "42540                            1                           0  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_idx = 1498715\n",
      "valid_idx = 1581977\n",
      "Training set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    0.808812\n",
       "0    0.191188\n",
       "Name: loan_status, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    0.82919\n",
       "0    0.17081\n",
       "Name: loan_status, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    0.80553\n",
       "0    0.19447\n",
       "Name: loan_status, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the rows into train/validation/test sets\n",
    "random_state = 42\n",
    "training_frac = 0.9\n",
    "valid_frac = 0.05\n",
    "\n",
    "train_idx = int(training_frac*len(loans_df))\n",
    "valid_idx = int((training_frac+valid_frac)*len(loans_df))\n",
    "print(f'train_idx = {train_idx}')\n",
    "print(f'valid_idx = {valid_idx}')\n",
    "\n",
    "loans_df.sample(frac=1, random_state=random_state)\n",
    "loans_df_training = loans_df.iloc[0:train_idx]\n",
    "loans_df_validation = loans_df.iloc[train_idx:valid_idx]\n",
    "loans_df_test = loans_df.iloc[valid_idx:]\n",
    "\n",
    "print('Training set:')\n",
    "display(loans_df_training['loan_status'].value_counts()/len(loans_df_training))\n",
    "print('Validation set:')\n",
    "display(loans_df_validation['loan_status'].value_counts()/len(loans_df_validation))\n",
    "print('Test set:')\n",
    "display(loans_df_test['loan_status'].value_counts()/len(loans_df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes:\n",
    "# Fully Paid == 1\n",
    "# Charged Off == 0\n",
    "num_classes = 2\n",
    "\n",
    "# Number of features are number of columns - 1 (from the output)\n",
    "num_features = len(loans_df.columns) - 1\n",
    "\n",
    "# Define inputs (X) and outputs (Y) for each set of samples\n",
    "Y_train = to_categorical(loans_df_training['loan_status'], num_classes)\n",
    "Y_valid = to_categorical(loans_df_validation['loan_status'], num_classes)\n",
    "Y_test = to_categorical(loans_df_test['loan_status'], num_classes)\n",
    "\n",
    "X_train = loans_df_training.drop(columns='loan_status').to_numpy().astype('float32')\n",
    "X_valid = loans_df_validation.drop(columns='loan_status').to_numpy().astype('float32')\n",
    "X_test = loans_df_test.drop(columns='loan_status').to_numpy().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features: 93\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of Features: {num_features}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 128)               12032     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 12,290\n",
      "Trainable params: 12,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "input_shape = (num_features,)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=input_shape, activation='relu'))\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1499/1499 [==============================] - 5s 3ms/step - loss: 216.0245 - accuracy: 0.9208 - val_loss: 12.4943 - val_accuracy: 0.9662\n",
      "Epoch 2/50\n",
      "1499/1499 [==============================] - 4s 3ms/step - loss: 62.5479 - accuracy: 0.9465 - val_loss: 27.6189 - val_accuracy: 0.9761\n",
      "Epoch 3/50\n",
      "1499/1499 [==============================] - 5s 3ms/step - loss: 66.6178 - accuracy: 0.9469 - val_loss: 11.9982 - val_accuracy: 0.9793\n",
      "Epoch 4/50\n",
      "1499/1499 [==============================] - 4s 3ms/step - loss: 48.5085 - accuracy: 0.9547 - val_loss: 12.6363 - val_accuracy: 0.9806\n",
      "Epoch 5/50\n",
      "1499/1499 [==============================] - 5s 3ms/step - loss: 59.9696 - accuracy: 0.9512 - val_loss: 312.1158 - val_accuracy: 0.5976\n",
      "Epoch 6/50\n",
      "1499/1499 [==============================] - 4s 3ms/step - loss: 44.2760 - accuracy: 0.9542 - val_loss: 11.3143 - val_accuracy: 0.9739 ETA: 0s - loss: 44.6049 - accuracy: 0.95\n",
      "Epoch 7/50\n",
      "1499/1499 [==============================] - 4s 3ms/step - loss: 42.1051 - accuracy: 0.9538 - val_loss: 91.5462 - val_accuracy: 0.8082\n",
      "Epoch 8/50\n",
      "1499/1499 [==============================] - 5s 3ms/step - loss: 38.3161 - accuracy: 0.9553 - val_loss: 8.6212 - val_accuracy: 0.9807\n",
      "Epoch 9/50\n",
      "1499/1499 [==============================] - 5s 3ms/step - loss: 38.5089 - accuracy: 0.9526 - val_loss: 8.8140 - val_accuracy: 0.9777\n",
      "Epoch 10/50\n",
      "1499/1499 [==============================] - 5s 3ms/step - loss: 23.2391 - accuracy: 0.9597 - val_loss: 8.5131 - val_accuracy: 0.9763\n",
      "Epoch 11/50\n",
      "1499/1499 [==============================] - 5s 4ms/step - loss: 29.3525 - accuracy: 0.9552 - val_loss: 7.7798 - val_accuracy: 0.9691\n",
      "Epoch 12/50\n",
      "1499/1499 [==============================] - 5s 4ms/step - loss: 24.4144 - accuracy: 0.9568 - val_loss: 27.7142 - val_accuracy: 0.8492\n",
      "Epoch 13/50\n",
      "1499/1499 [==============================] - 5s 3ms/step - loss: 26.2475 - accuracy: 0.9537 - val_loss: 16.5413 - val_accuracy: 0.9714\n",
      "Epoch 14/50\n",
      "1499/1499 [==============================] - 5s 3ms/step - loss: 19.8748 - accuracy: 0.9597 - val_loss: 6.4594 - val_accuracy: 0.9802\n",
      "Epoch 15/50\n",
      "1499/1499 [==============================] - 5s 3ms/step - loss: 23.5648 - accuracy: 0.9553 - val_loss: 5.8017 - val_accuracy: 0.9793\n",
      "Epoch 16/50\n",
      "1499/1499 [==============================] - 4s 3ms/step - loss: 21.1976 - accuracy: 0.9571 - val_loss: 6.4665 - val_accuracy: 0.9602\n",
      "Epoch 17/50\n",
      "1499/1499 [==============================] - 5s 3ms/step - loss: 18.2515 - accuracy: 0.9582 - val_loss: 141.0905 - val_accuracy: 0.9242\n",
      "Epoch 18/50\n",
      "1499/1499 [==============================] - 4s 3ms/step - loss: 15.6037 - accuracy: 0.9590 - val_loss: 7.2524 - val_accuracy: 0.9386\n",
      "Epoch 19/50\n",
      "1499/1499 [==============================] - 4s 3ms/step - loss: 12.6601 - accuracy: 0.9600 - val_loss: 6.6437 - val_accuracy: 0.9779\n",
      "Epoch 20/50\n",
      "1499/1499 [==============================] - 5s 3ms/step - loss: 13.1942 - accuracy: 0.9593 - val_loss: 3.5936 - val_accuracy: 0.9649\n",
      "Epoch 21/50\n",
      "1499/1499 [==============================] - 5s 3ms/step - loss: 16.8784 - accuracy: 0.9584 - val_loss: 4.0930 - val_accuracy: 0.9585\n",
      "Epoch 22/50\n",
      "1499/1499 [==============================] - 4s 3ms/step - loss: 14.3142 - accuracy: 0.9591 - val_loss: 4.3241 - val_accuracy: 0.9807\n",
      "Epoch 23/50\n",
      "1499/1499 [==============================] - 4s 3ms/step - loss: 13.6238 - accuracy: 0.9608 - val_loss: 3.0321 - val_accuracy: 0.9758\n",
      "Epoch 24/50\n",
      "1499/1499 [==============================] - 4s 3ms/step - loss: 10.4163 - accuracy: 0.9615 - val_loss: 6.9465 - val_accuracy: 0.9810\n",
      "Epoch 25/50\n",
      "1499/1499 [==============================] - 4s 3ms/step - loss: 11.4599 - accuracy: 0.9616 - val_loss: 2.5978 - val_accuracy: 0.9802\n",
      "Epoch 26/50\n",
      "1499/1499 [==============================] - 4s 3ms/step - loss: 10.8440 - accuracy: 0.9626 - val_loss: 11.8235 - val_accuracy: 0.9802\n",
      "Epoch 27/50\n",
      "1499/1499 [==============================] - 4s 3ms/step - loss: 11.2207 - accuracy: 0.9622 - val_loss: 7.9566 - val_accuracy: 0.9809\n",
      "Epoch 28/50\n",
      "1499/1499 [==============================] - 4s 2ms/step - loss: 11.3240 - accuracy: 0.9632 - val_loss: 15.3346 - val_accuracy: 0.9801\n",
      "Epoch 29/50\n",
      "1499/1499 [==============================] - 4s 2ms/step - loss: 9.2554 - accuracy: 0.9629 - val_loss: 36.1241 - val_accuracy: 0.9681\n",
      "Epoch 30/50\n",
      "1499/1499 [==============================] - 4s 2ms/step - loss: 10.7178 - accuracy: 0.9627 - val_loss: 3.0761 - val_accuracy: 0.9767\n",
      "Epoch 31/50\n",
      "1499/1499 [==============================] - 4s 2ms/step - loss: 7.9014 - accuracy: 0.9641 - val_loss: 1.7233 - val_accuracy: 0.9812\n",
      "Epoch 32/50\n",
      "1499/1499 [==============================] - 4s 3ms/step - loss: 6.6292 - accuracy: 0.9628 - val_loss: 2.5967 - val_accuracy: 0.9795\n",
      "Epoch 33/50\n",
      "1499/1499 [==============================] - 6s 4ms/step - loss: 4.9640 - accuracy: 0.9626 - val_loss: 3.2567 - val_accuracy: 0.9029\n",
      "Epoch 34/50\n",
      "1499/1499 [==============================] - 4s 2ms/step - loss: 5.6134 - accuracy: 0.9643 - val_loss: 1.6915 - val_accuracy: 0.9838\n",
      "Epoch 35/50\n",
      "1499/1499 [==============================] - 4s 2ms/step - loss: 4.3620 - accuracy: 0.9632 - val_loss: 1.9463 - val_accuracy: 0.9852\n",
      "Epoch 36/50\n",
      "1499/1499 [==============================] - 4s 2ms/step - loss: 3.0127 - accuracy: 0.9652 - val_loss: 0.9081 - val_accuracy: 0.9820\n",
      "Epoch 37/50\n",
      "1499/1499 [==============================] - 4s 3ms/step - loss: 3.1775 - accuracy: 0.9637 - val_loss: 0.3838 - val_accuracy: 0.9833\n",
      "Epoch 38/50\n",
      "1499/1499 [==============================] - 4s 3ms/step - loss: 3.2598 - accuracy: 0.9633 - val_loss: 0.4011 - val_accuracy: 0.9830\n",
      "Epoch 39/50\n",
      "1499/1499 [==============================] - 4s 2ms/step - loss: 2.6251 - accuracy: 0.9640 - val_loss: 3.0074 - val_accuracy: 0.9804\n",
      "Epoch 40/50\n",
      "1499/1499 [==============================] - 4s 3ms/step - loss: 1.6253 - accuracy: 0.9650 - val_loss: 0.2089 - val_accuracy: 0.9821\n",
      "Epoch 41/50\n",
      "1499/1499 [==============================] - 4s 2ms/step - loss: 1.6704 - accuracy: 0.9646 - val_loss: 1.9258 - val_accuracy: 0.9808\n",
      "Epoch 42/50\n",
      "1499/1499 [==============================] - 4s 3ms/step - loss: 1.0702 - accuracy: 0.9675 - val_loss: 1.8036 - val_accuracy: 0.9742\n",
      "Epoch 43/50\n",
      "1499/1499 [==============================] - 4s 2ms/step - loss: 0.7117 - accuracy: 0.9622 - val_loss: 0.2535 - val_accuracy: 0.9770\n",
      "Epoch 44/50\n",
      "1499/1499 [==============================] - 4s 2ms/step - loss: 0.3737 - accuracy: 0.9719 - val_loss: 0.0759 - val_accuracy: 0.9864\n",
      "Epoch 45/50\n",
      "1499/1499 [==============================] - 4s 2ms/step - loss: 0.1574 - accuracy: 0.9778 - val_loss: 0.0837 - val_accuracy: 0.9838\n",
      "Epoch 46/50\n",
      "1499/1499 [==============================] - 4s 2ms/step - loss: 0.1217 - accuracy: 0.9771 - val_loss: 0.0649 - val_accuracy: 0.9875\n",
      "Epoch 47/50\n",
      "1499/1499 [==============================] - 4s 2ms/step - loss: 0.0885 - accuracy: 0.9815 - val_loss: 0.0609 - val_accuracy: 0.9881\n",
      "Epoch 48/50\n",
      "1499/1499 [==============================] - 4s 3ms/step - loss: 0.0877 - accuracy: 0.9811 - val_loss: 0.0612 - val_accuracy: 0.9878\n",
      "Epoch 49/50\n",
      "1499/1499 [==============================] - 4s 2ms/step - loss: 0.0878 - accuracy: 0.9809 - val_loss: 0.0621 - val_accuracy: 0.9873\n",
      "Epoch 50/50\n",
      "1499/1499 [==============================] - 4s 2ms/step - loss: 0.0891 - accuracy: 0.9804 - val_loss: 0.0702 - val_accuracy: 0.9827\n"
     ]
    }
   ],
   "source": [
    "# Configure model and start training\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, epochs=50, batch_size=1000, verbose=1, validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_predict = (model.predict(X_train) > 0.5).astype('float32')\n",
    "Y_test_predict = (model.predict(X_test) > 0.5).astype('float32')\n",
    "Y_valid_predict = (model.predict(X_valid) > 0.5).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set miss: 2.3740337555839504%\n",
      "Validation set miss: 1.7258773510124665%\n",
      "Test set miss: 1.385986404362134%\n"
     ]
    }
   ],
   "source": [
    "train_miss = np.abs((Y_train_predict - Y_train)).sum()/2/len(Y_train)*100\n",
    "validation_miss = np.abs((Y_valid_predict - Y_valid)).sum()/2/len(Y_valid)*100\n",
    "test_miss = np.abs((Y_test_predict - Y_test)).sum()/2/len(Y_test)*100\n",
    "\n",
    "print(f'Training set miss: {train_miss}%')\n",
    "print(f'Validation set miss: {validation_miss}%')\n",
    "print(f'Test set miss: {test_miss}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 2.0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax= plt.subplots()\n",
    "ax.plot(history.history['val_loss'])\n",
    "ax.set_ylim(0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
